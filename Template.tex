\documentclass[xcolor={table}, aspectratio=169]{beamer}
%
% Choose how your presentation looks.
%
% For more themes, color themes and font themes, see:
% http://deic.uab.es/~iblanes/beamer_gallery/index_by_theme.html
%
\defbeamertemplate{footline}{my frame number}
{
    \hfill
    \usebeamercolor[fg]{page number in head/foot}
    \usebeamerfont{page number in head/foot}
    \raisebox{0.25cm}[0pt][0pt]{
        \insertframenumber\kern1em}
}
\mode<presentation>
{
    \usetheme{default}
    \usecolortheme{seagull}
    \usefonttheme{default}
    \setbeamertemplate{caption}[numbered]
    \setbeamertemplate{footline}[my frame number]
    \setbeamertemplate{navigation symbols}{}
    \addtobeamertemplate{frametitle}{\vskip+0.5ex}{}
}
% \AtBeginSection[] {
%     \begin{frame}<beamer>
%     \frametitle{Outline}
%     \tableofcontents[currentsection]
%     \end{frame}
% }
% \AtBeginSubsection[] {
%     \begin{frame}<beamer>
%     \frametitle{Outline}
%     \tableofcontents[currentsection, currentsubsection]
%     \end{frame}
% }

\usepackage[english]{babel}
\usepackage[export]{adjustbox}
\usepackage[permil]{overpic}
\usepackage{threeparttable}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{setspace}
\usepackage{ulem}
\usepackage{amssymb}
\usepackage{subcaption}
\usepackage{psfrag}
%\usepackage{natbib}
\usepackage[autocite=superscript,backend=bibtex, style=authoryear]{biblatex}
\addbibresource{refs.bib}

\usepackage{multirow}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{color}
% \usepackage{cleveref}
\usepackage[font=scriptsize]{caption}
\usepackage{booktabs}
\usepackage{amsmath}

\usepackage{siunitx}

\sisetup{output-exponent-marker=\ensuremath{\mathrm{e}}}



%\usepackage{fontspec}

\graphicspath{{stevens/}{figures/}}

\makeatletter
\def\beamer@framenotesbegin{% at beginning of slide
     \usebeamercolor[fg]{normal text}
      \gdef\beamer@noteitems{}%
      \gdef\beamer@notes{}%
}
\makeatother

\usebackgroundtemplate
{
    \begin{tabular}{@{}c@{}}
        \includegraphics[width=\paperwidth]{presentation_top.png} \\
        \rule{0pt}{0.74\paperheight} \\
        \includegraphics[width=\paperwidth]{presentation_bottom.png}
    \end{tabular}
}

\vspace{1cm}

\title[Lit Review]
      {Phase Two Presentation: RL vs. Naive Diversification\\
      \large{Robustness and Frictions Across Market Regimes}}

\author[Author] % (optional, use only with lots of authors)
{Andre Sealy}
% - Use the \inst{?} command only if the authors have different
%   affiliation.

\institute[Stevens Institute] % (optional, but mostly needed)
{
	Advisor: Jingrui (Victoria) Li\\
  Financial Engineering 800\\
  Stevens Institute of Technology\\
%System description details at \cite{w2020shift}}
}
\date{\\
{\footnotesize November 18th, 2025}}

\subject{Talk at Venue}


%\author[Ionut Florescu]{\texorpdfstring{\footnotesize Ionu\c{t} Florescu \\
%       \vspace*{0.5\baselineskip}
%     {\footnotesize Committee: \\
%      Dr. George Calhoun, Dr. Drago»ô Bozdog, \\
%      Dr. Emmanuel Hatzakis, Dr. Rupak Chatterjee}}{Ionu\c{t} Florescu}}
% \institute{\footnotesize Financial Engineering}
% \date{{\footnotesize September 12, 2020}}

\begin{document}

{
\setbeamertemplate{footline}{}
\usebackgroundtemplate
{
	\begin{tabular}{@{}c@{}}
		\begin{overpic}[width=\paperwidth]{title_top.png}
			\put(25,-35){\includegraphics[height=0.15\paperheight]{title_logo.png}}
		\end{overpic} \\
		\rule{0pt}{0.74\paperheight}                     \\
		\includegraphics[width=\paperwidth]{title_bottom.png}
	\end{tabular}
}

\begin{frame}

	\titlepage

\end{frame}
}

\begin{frame}{Overview}

	\begin{itemize}
		\item Addressing the stationarity issues of the Decision Transformer.
		      \newline
		\item Addressing the computational issues with extracting state trajectories for the
		      Decision Transformer.
		      \newline
		\item Model updates and performance.
	\end{itemize}

\end{frame}

\begin{frame}
	\centering
	\vfill
	{\Large \textbf{Background}}
	\vfill
\end{frame}
\begin{frame}{Reinforcement Learning Environment}

	Recall the environment, $\mathcal{M}$, which we have established with the following parameters

	\[
		\mathcal{M}=\left(\mathcal{S},\mathcal{A},P,\mathcal{R},\Theta\right)
	\]
	where
	\begin{itemize}
		\item $\mathcal{A}\in\mathbb{R}^N$ is the action space, where $N$ are the number of assets.
		\item $\mathcal{S}$ is the state space, which is a linear combination of different position states.
		\item $P$ are the transition dynamics governed by market dynamics and portfolio evolution.
		\item $\mathcal{R}$ is the reward function or the return on the portfolio.
		\item $\Theta$ are the custom trading parameters
	\end{itemize}
\end{frame}

\begin{frame}{Reinforcement Learning Environment}

	The custom parameters of $\Theta$ are denoted by the following:
	\[
		\Theta =
		\begin{cases}
			H_{\max},              & H_{\max}=100   \\
			V_0\in\mathbb{R}^+     & V_0=1,000,000  \\
			\tau\in[0,1),          & \tau=0.005     \\
			N\in\mathbb{N},        & N=394          \\
			I\in\mathbb{N},        & I=8            \\
			K\in\mathbb{N},        & K=2            \\
			\alpha\in\mathbb{R}^+, & \alpha=10^{-1} \\
		\end{cases}
	\]
	where $H_{\max}$ is the maximum shares traded per stock, $V_0$ is the initial portfolio value, $\tau$ is the transaction cost percentage, $N$ are the number of assets, $\alpha$ is the reward scaling factor, $I$ and $K$ are the number of indicators and regime variables respectively.
\end{frame}

\begin{frame}
	\centering
	\vfill
	{\Large \textbf{Stationarity Issues}}
	\vfill
\end{frame}

\begin{frame}{Stationarity Issues}
	Running reinforcement learning (RL) algorithms with a decision transformer (DT) across many
	different states introduces stationarity issues, such as
	\begin{itemize}
		\item \textbf{Stationarity and Regime Shift:}  DT may conflate regimes, failing to recognize when a feature distribution changes.
		\item \textbf{Poor Feature Scaling and Instability:} Transformer architectures are sensitive
		      to outliers and input scale.
		\item \textbf{Empaired Risk and Exposure Control:} The DT may unknowingly overweight risky
		      assets in high-volatility regimes or fail to detect regime-dependent risk.
	\end{itemize}
\end{frame}

\begin{frame}{State Statistics}
	State statistics help us diagnose market structures and create tailored signals for robust model
	training and evaluation. The purpose issues
	\begin{itemize}
		\item \textbf{Characterize Market Environments:} State statistics quantify the typical and extreme behaviors of the features that describe the market or economic regimes.
		\item \textbf{Enable Regime-Specific Modeling:} By segmenting historical data based on regime labels, conditional statistics can be computed.
		\item \textbf{Support Feature Engineering and Normalization:} Aggregate statistics allow for robust feature scaling, improved training stability, and the direction of non-stationarities or structural breaks across different periods
	\end{itemize}
\end{frame}

\begin{frame}{State Statistics}
	\begin{itemize}
		\item \textbf{Mean:} Central tendency of a state feature.
		      \[
			      \mu=\frac{1}{N}\sum_{i=1}^{N}x^{(i)}
		      \]
		\item \textbf{Variance and Standard Deviation:} Measure the dispersion or risk.
		      \[
			      \sigma^2=\frac{1}{N}\sum_{i=1}^{N}\left(x^{(i)}-\mu\right)^2
		      \]
		\item \textbf{Covariance and Correlation:} Quantify comovements.
		      \[
			      \text{Cov}(x,y)=\frac{1}{N}\sum_{i=1}^{N}\left(x^{(i)}-\mu_{x}\right)\left(y^{(i)}-\mu_{y}\right),\quad\rho_{xy}=\frac{\text{Cov}(x,y)}{\sigma_{x}\sigma_{y}}
		      \]
	\end{itemize}
\end{frame}

\begin{frame}{State Statistics}
	Utilizing state statistics for Transformers is supported by research from Liu, Wu, Wang, and Long (2022).

	\begin{figure}
		\centering
		\includegraphics[width=0.8\textwidth]{./pics/non_stationarity.png}
		\caption{Visualization of learned temporal attentions for different series with varied mean
			$\mu$ and standard deviation $\sigma$.}
	\end{figure}
\end{frame}

\begin{frame}
	\centering
	\vfill
	{\Large \textbf{Computational Issues}}
	\vfill
\end{frame}

\begin{frame}{Trajectories}

	Recall that DT frames RL problems as a sequence modeling problem, which leverages the
	mathematics and architecture of Transformer models by training pre-collected (offline)
	trajectories and encoding each input sequence to predict future returns.

\end{frame}

\begin{frame}{Trajectories}
	Recall the sequence of states, actions, and rewards collected over time $s_t,a_t,r_t$ and the state, action, and reward at timestep $t$. This sequence is defined as the \textbf{trajectory} in the MDP, defined by the following:
	\[
		\tau=\lbrace\left(s_0,a_0,r_0\right),(s_1,a_1,r_1),\ldots,(s_T,a_T,r_T) \rbrace,
	\]
	where $T$ is denotes the final timestep in the trajectory.
\end{frame}

\begin{frame}{Trajectories}
	This process of encoding trajectories is computationally expensive because the process involves
	collecting entire episodes of agent-environment interactions and handling, storing, and
	processing large datasets.
\end{frame}

\begin{frame}{Computational Issues}
	Running reinforcement learning (RL) algorithms with decision transformers (DT) across many different states introduces several computational challenges, such as,
	\begin{itemize}
		\item \textbf{High Memory Requirements:} Significant amounts of memory are required for storing and processing trajectories.
		\item \textbf{Data Inefficiencies:} Many different states demand more samples to cover the space adequately, compounding dataset size and training time.
		\item \textbf{Sequence Alignment and Temporal Credit Assignment:} The more states the DT has, aligning and credit outcomes to earlier actions becomes computationally more difficult.
		\item \textbf{Model Size and Training Cost:} DT may need larger transformer models, which require more computational resources, longer training times, and powerful hardware.
	\end{itemize}
\end{frame}

\begin{frame}{High Performance Computing}
	High-performance computing (HPC) can significantly accelerate research on RL for portfolio optimization, especially when using computationally demanding models like decision transformers in complex regimes.
	\begin{itemize}
		\item \textbf{Parallelization and Speed:} HPC environments allows computational to be distributed across many CPUs and GPUs, drastically reducing the time for training RL models and grid searches over hyperparameters.
		\item \textbf{Larger Models and Datasets:} We can train deeper transformer architectures and process longer trajectories or higher-dimensional state spaces, overcoming the memory and compute limits of a regular PC.
		\item \textbf{Handling Frictions and Constraints:} Simulating realistic trading frictions (transaction costs, slippage, etc.) requires substantial computation and state tracking.
	\end{itemize}
\end{frame}

\begin{frame}{JARVIS}
	\begin{columns}
		\column{0.6\textwidth}
		Stevens Institute of Technology's HPC cluster JARVIS is a state-of-the-art computing resource designed to support advanced research across the university.
		\begin{itemize}
			\item \textbf{Compute Resources:} JARVIS consists 55 codes, providing 3,168 CPU cores and 32 GPUs, including 8 advanced Nvidia L40s GPUs.
			\item \textbf{Memory:} The cluster has 14 TBs of memory, which enables it to handle complex, memory-intensive workloads.
			\item \textbf{Storage:} It includes 1.2 petabytes (PB) of storage, supporting larged dataset and model checkpoint management.
		\end{itemize}
		\column{0.5\textwidth}
		\begin{figure}
			\includegraphics[width=1.\textwidth]{./pics/jarvis.jpeg}
			\caption{Not actually Steven's JARVIS}
		\end{figure}
	\end{columns}
\end{frame}

\begin{frame}{Workstation Computational Comparisons}
	\begin{table}[htbp]
		\centering
		\caption{Benchmark of DT Runtime with Various Computer Specs.}
		\label{tab:logrent_regression}

		{\scriptsize
			\begin{tabular}{lcccc}
				\toprule
				                                     &                    & Hanlon              & \$ 10 Million          & JARVIS               \\
				                                     &                    & Lab                 & Studio (mine)          &                      \\
				\midrule
				\textit{Workstation Specifications:} &                    &                     &                        &                      \\
				\quad  CPU                           &                    & Intel i9-11900      & AMD Ryzen 9 5950X      & Intel                \\
				\quad  GPU                           &                    & NVIDIA GeForce 3070 & NVIDIA GeForce 4090 TI & NVIDIA
				L40S                                                                                                                            \\
				\quad  Memory                        &                    & 64GB (2x32 GB)      & 128GB (4x32
				GB)                                  & 17TB                                                                                     \\
				\midrule
				Runtime Detection                    &                    & GPU                 & GPU
				                                     & CPU or GPU                                                                               \\
				Total Training Steps                 &                    & 600,000             & 1,000,000
				                                     & Significantly more                                                                       \\
				Total Runtime$                       &                    & 125 Hours           & 27 hours               & Significantly faster \\
				Crashes Occasionally?                &                    & \checkmark          &                        &                      \\
				\bottomrule
			\end{tabular}
		} % end scriptsize group

	\end{table}
\end{frame}
\begin{frame}{Model Updates}
	\begin{figure}
		\centering
		\includegraphics[width=0.9\textwidth]{./pics/ticket.png}
		\caption{Ticket with Tech Support Approving JARVIS Access.}
	\end{figure}
\end{frame}

\begin{frame}
	\centering
	\vfill
	{\Large \textbf{Model updates}}
	\vfill
\end{frame}

\begin{frame}{Model Updates}
	\begin{itemize}
		\item Incorporating state statistics to summarize the behavior and properties of the states
		      encountered by the RL agent.
		\item Incorporating macroeconomic variables for regime detection in accordance with the
		      Chen, Peiger, and Zhu paper (Deep Learning in Asset Pricing)
		\item Including a single regime increased the state size from 3,931 to 4,324.
	\end{itemize}

\end{frame}

\begin{frame}{Model Updates}
	\begin{figure}
		\centering
		\includegraphics[width=1\textwidth]{./pics/regimes.png}
		\caption{Macroeconomic Regimes to be included in the Decision Transformer.}
	\end{figure}
\end{frame}

\begin{frame}{Model Updates}
	\begin{figure}
		\centering
		\includegraphics[width=1\textwidth]{./pics/performance.png}
		\caption{Performance of Decision Transformer and PPO with and without regimes}
	\end{figure}
\end{frame}

\begin{frame}
	\begin{table}[htbp]
		\centering
		\caption{Reinforcement Learning Algorithms Parameters}
		\label{tab:logrent_regression}
		\begin{tabular}{lccccc}
			\toprule
			                          &  &  & Naive     & DT        & PPO       \\
			\midrule
			\textit{Without Regimes:} &  &  &           &           &           \\
			\quad Annual Return       &  &  & 0.151657  & 0.160969  & 0.187503  \\
			\quad Sharpe Ratio        &  &  & 0.98472   & 1.071349  & 1.300689  \\
			\quad Max Drawdown        &  &  & -0.155387 & -0.145308 & -0.122458 \\
			                          &  &  &           &           &           \\
			\textit{With Regimes:}    &  &  &           &           &           \\
			\quad Annual Return       &  &  & 0.151657  & 0.148791  & 0.249243  \\
			\quad Sharpe Ratio        &  &  & 0.98472   & 0.966856  & 0.15500   \\
			\quad Max Drawdown        &  &  & -0.155387 & -0.150140 & -0.159952 \\
			                          &  &  &           &           &           \\
			\bottomrule
		\end{tabular}
	\end{table}
\end{frame}

\begin{frame}
	\centering
	\vfill
	{\Large \textbf{Next Steps}}
	\vfill
\end{frame}

\begin{frame}{Next Steps}
	The following steps will be incorporated, as soon as I figure out how JARVIS works
	\begin{itemize}
		\item Increasing the step size and credit assignment for the model.
		\item Work with different regimes (unemployment, oil prices, interest rates, etc.).
		\item Increase the number of assets.
	\end{itemize}
\end{frame}

\begin{frame}
	\centering
	\vfill
	{\Large \textbf{Questions?}}
	\vfill
\end{frame}

\end{document}
